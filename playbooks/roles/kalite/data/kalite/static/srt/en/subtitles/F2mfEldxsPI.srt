1
00:00:00,200 --> 00:00:04,211
Here's a simulations created by Khan Academy user Justin Helps

2
00:00:04,211 --> 00:00:08,854
that once again tries to give us an understanding of why we divide by n-1

3
00:00:08,854 --> 00:00:13,914
to get an unbiased estimate of population variance when we're trying to calculate the sample variance.

4
00:00:13,914 --> 00:00:19,011
So what he does here is a simulation it has a population that has a uniform distribution

5
00:00:19,011 --> 00:00:24,851
so he says "I used a flat probabilistic distribution from 0 to 200 for my population.

6
00:00:24,851 --> 00:00:29,208
Then we start sampling from that population, we're going to use samples of size 50

7
00:00:29,208 --> 00:00:34,490
and what we do is for each of those samples we calculate the variance based on dividing by n,

8
00:00:34,490 --> 00:00:40,427
we calculate the sample variance based on dividing by n, by dividing by n-1 and n-2

9
00:00:40,427 --> 00:00:46,234
and as we keep having more and more and more samples, we take the mean of the variances calculated in

10
00:00:46,234 --> 00:00:48,718
different ways and we figure out what those means converge to

11
00:00:48,718 --> 00:00:51,245
so that's a sample, here's another sample, here's another sample

12
00:00:51,245 --> 00:00:56,190
if I sample here then now I'm adding a bunch and I'm sampling continuously

13
00:00:56,190 --> 00:01:04,614
And you saw something very interesting happen. When I divide by n, I get my sample variance

14
00:01:04,614 --> 00:01:09,931
is still (even when I'm taking the mean of many many many sample variances) that I've already taken I'm

15
00:01:09,931 --> 00:01:12,681
still underestimating the true variance.

16
00:01:12,863 --> 00:01:16,288
When I divide by n-1 it looks like I'm getting a pretty good estimate

17
00:01:16,288 --> 00:01:20,130
the mean of all of my sample variances has really converged to the true variance

18
00:01:20,130 --> 00:01:24,677
when I divided by n-2 just for kicks it is pretty clear that I overestimated

19
00:01:24,677 --> 00:01:31,937
that I overestimated the.. with my mean of my sample variances I overestimated the true

20
00:01:31,937 --> 00:01:36,345
variance. So this gives us a pretty good sense that n-1 is the right thing to do.

21
00:01:36,345 --> 00:01:39,698
Now this is another interesting way of visualizing it

22
00:01:39,698 --> 00:01:46,785
In the horizontal axis right over here we're comparing each plot is one of our samples and how far to the right

23
00:01:46,785 --> 00:01:51,445
is how much more is that sample mean than the true mean and when we go to the left is

24
00:01:51,445 --> 00:01:54,294
how much less is the sample mean from the true mean.

25
00:01:54,294 --> 00:02:00,051
So for example this sample right over here it's all the way over to the right, it's the sample mean there is a lot more

26
00:02:00,051 --> 00:02:04,553
than the true mean, sample mean here was a lot less than the true mean, sample mean here only a little

27
00:02:04,553 --> 00:02:11,195
bit more than the true mean. In the vertical axis, using this denominator dividing by n, we calculate

28
00:02:11,195 --> 00:02:16,848
two different variances: one variance we use the sample mean, the other variance

29
00:02:16,848 --> 00:02:22,738
we use the population mean. And this the vertical axis we compare the difference between

30
00:02:22,738 --> 00:02:27,390
the mean calculated with the sample mean versus the mean calculated with the population mean

31
00:02:27,390 --> 00:02:32,310
So for example, this point right over here, when we calculate our mean with our

32
00:02:32,310 --> 00:02:36,308
sample mean, which is the normal way we do it, it significantly underestimates

33
00:02:36,308 --> 00:02:40,212
what the mean would have been if somehow we knew what the population mean was

34
00:02:40,212 --> 00:02:44,580
and we could calculate it that way and you get this really interesting shape

35
00:02:44,580 --> 00:02:48,714
and that's something to think about if you recommend something to think about why or what

36
00:02:48,714 --> 00:02:52,313
kind of shape this actually is. The other interesting thing is

37
00:02:52,556 --> 00:02:58,462
when you look at it this way it's pretty clear this entire graph is sitting below the horizontal axis

38
00:02:58,462 --> 00:03:03,134
so we're always when we calculate our sample variance using this formula

39
00:03:03,134 --> 00:03:09,369
what when we use the sample mean to do it, which we typically do, we're always underestimating

40
00:03:09,369 --> 00:03:14,862
we're always getting a lower variance than when we use the population mean

41
00:03:14,862 --> 00:03:19,993
Now this over here, when we divide by n-1 we're not always underestimating

42
00:03:19,993 --> 00:03:23,629
sometimes we're overestimating and when you take the mean of all of these variances

43
00:03:23,629 --> 00:03:28,053
you converge, and here we're overestimating a little bit more

44
00:03:28,053 --> 00:03:30,601
and just to be clear what we're talking about with these three graphs

45
00:03:30,601 --> 00:03:35,305
let me take a screen shot of it and explain it a little more in depth

46
00:03:35,305 --> 00:03:39,366
so just to be clear, just to be clear, this red graph right over here

47
00:03:39,366 --> 00:03:44,478
let me do this color close to at least, so this orange, what this distance is

48
00:03:44,478 --> 00:03:48,902
for each of these samples we're calculating the sample variance

49
00:03:48,902 --> 00:04:00,122
using the sample mean and in this case we are using n as our denominator in this case

50
00:04:00,122 --> 00:04:05,100
right over here, and from that we're subtracting the sample variance

51
00:04:05,100 --> 00:04:08,508
or I guess you could call this some type of pseudo sample variance

52
00:04:08,508 --> 00:04:12,982
if we somehow knew the population mean, this isn't something you see in a lot of statistics

53
00:04:12,982 --> 00:04:19,916
but it's a gauge of how much we are underestimating our sample, our our sample variance given

54
00:04:19,916 --> 00:04:25,650
that we do not have the true population mean at our disposal

55
00:04:25,650 --> 00:04:30,490
so this is the distance we're calculating. So you see we are always, always underestimating.

56
00:04:30,490 --> 00:04:36,664
Here we overestimate a little bit, and we also underestimate, but when you take the mean

57
00:04:36,664 --> 00:04:40,132
and average them all out it converges to the actual values

58
00:04:40,132 --> 00:04:44,132
So here we're dividing by n-1 and here we're dividing by n-2
