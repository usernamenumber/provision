1
00:00:00,000 --> 00:00:00,370
   

2
00:00:00,370 --> 00:00:03,470
What I want to do in this video
is build up some tools

3
00:00:03,470 --> 00:00:07,720
in our tool kit for dealing with
sums and differences of

4
00:00:07,720 --> 00:00:08,740
random variables.

5
00:00:08,740 --> 00:00:13,650
So let's say that we have two
random variables, x and y, and

6
00:00:13,650 --> 00:00:15,660
they are completely
independent.

7
00:00:15,660 --> 00:00:20,280
They are independent
random variables.

8
00:00:20,280 --> 00:00:24,770
   

9
00:00:24,770 --> 00:00:26,090
And I'm just going to
go over a little bit

10
00:00:26,090 --> 00:00:27,440
of a notation here.

11
00:00:27,440 --> 00:00:30,730
If we wanted to know the
expected, or if we talked

12
00:00:30,730 --> 00:00:34,960
about the expected value of this
random variable x, that

13
00:00:34,960 --> 00:00:39,670
is the same thing as the
mean value of this

14
00:00:39,670 --> 00:00:41,130
random variable x.

15
00:00:41,130 --> 00:00:48,540
If we talk about the expected
the value of y, that is the

16
00:00:48,540 --> 00:00:53,080
same thing as the mean of y.

17
00:00:53,080 --> 00:01:00,350
If we talk about the variance of
the random variable x, that

18
00:01:00,350 --> 00:01:05,670
is it the same thing as the
expected value of the squared

19
00:01:05,670 --> 00:01:11,210
distances between our random
variable x and its mean.

20
00:01:11,210 --> 00:01:13,270
And that right there squared.

21
00:01:13,270 --> 00:01:19,790
So the expected value of these
squared differences, and that

22
00:01:19,790 --> 00:01:24,120
you could also use the notation
sigma squared for the

23
00:01:24,120 --> 00:01:25,560
random variable x.

24
00:01:25,560 --> 00:01:27,670
This is just a review of things
we already know, but I

25
00:01:27,670 --> 00:01:30,920
just want to reintroduce it
because I'll use this to build

26
00:01:30,920 --> 00:01:32,770
up some of our tools.

27
00:01:32,770 --> 00:01:35,390
So you do the same thing with
this with random variable y.

28
00:01:35,390 --> 00:01:40,090
The variance of random variable
y is the expected

29
00:01:40,090 --> 00:01:44,030
value of the squared difference
between our random

30
00:01:44,030 --> 00:01:50,960
variable y and the
mean of y, or the

31
00:01:50,960 --> 00:01:53,790
expected value of y, squared.

32
00:01:53,790 --> 00:01:59,000
And that's the same thing
as sigma squared of y.

33
00:01:59,000 --> 00:02:01,570
There is the variance of y.

34
00:02:01,570 --> 00:02:05,180
Now you may or may not already
know these properties of

35
00:02:05,180 --> 00:02:07,360
expected values and variances,
but I will

36
00:02:07,360 --> 00:02:08,330
reintroduce them to you.

37
00:02:08,330 --> 00:02:10,500
And I won't go into some
rigorous proof-- actually, I

38
00:02:10,500 --> 00:02:12,890
think they're fairly
easy to digest.

39
00:02:12,890 --> 00:02:17,080
So one is is that if I have some
third random variable,

40
00:02:17,080 --> 00:02:19,100
let's say I have some third
random variable that is

41
00:02:19,100 --> 00:02:23,070
defined as being the random
variable x plus the random

42
00:02:23,070 --> 00:02:23,620
variable y.

43
00:02:23,620 --> 00:02:25,760
Let me stay with my
colors just so

44
00:02:25,760 --> 00:02:27,210
everything becomes clear.

45
00:02:27,210 --> 00:02:33,260
The random variable x plus
the random variable y.

46
00:02:33,260 --> 00:02:36,400
What is the expected value
of z going to be?

47
00:02:36,400 --> 00:02:40,720
The expected the value of z is
going to be equal to the

48
00:02:40,720 --> 00:02:44,090
expected value of x plus y.

49
00:02:44,090 --> 00:02:46,190
And this is a property of
expected values-- I'm not

50
00:02:46,190 --> 00:02:48,760
going to prove it rigorously
right here-- but the expected

51
00:02:48,760 --> 00:02:54,610
value of x plus the expected
value of y, or another way to

52
00:02:54,610 --> 00:02:58,940
think about this is that the
mean of z is going to be the

53
00:02:58,940 --> 00:03:04,340
mean of x plus the mean of y.

54
00:03:04,340 --> 00:03:08,220
Or another way to view it is if
I wanted to take, let's say

55
00:03:08,220 --> 00:03:10,240
I have some other
random variable.

56
00:03:10,240 --> 00:03:11,370
I'm running out of
letters here.

57
00:03:11,370 --> 00:03:14,760
Let's say I have the random
variable a, and I define

58
00:03:14,760 --> 00:03:18,790
random variable a
to be x minus y.

59
00:03:18,790 --> 00:03:21,280
So what's its expected
value going to be?

60
00:03:21,280 --> 00:03:24,830
The expected value of a is
going to be equal to the

61
00:03:24,830 --> 00:03:29,750
expected value of x minus y,
which is equal to-- you could

62
00:03:29,750 --> 00:03:32,920
either view it as the expected
value of x plus the expected

63
00:03:32,920 --> 00:03:38,970
value of negative y, or the
expected value of x minus the

64
00:03:38,970 --> 00:03:44,310
expected value of y, which is
the same thing as the mean of

65
00:03:44,310 --> 00:03:47,680
x minus the mean of y.

66
00:03:47,680 --> 00:03:52,520
So this is what the mean of
our random variable a

67
00:03:52,520 --> 00:03:54,180
would be equal to.

68
00:03:54,180 --> 00:03:56,700
And all of this is review and
I'm going to use this when we

69
00:03:56,700 --> 00:03:59,140
start talking about the
distributions that are sums

70
00:03:59,140 --> 00:04:01,580
and differences of other
distributions.

71
00:04:01,580 --> 00:04:05,610
Now let's think about what the
variance of random variable z

72
00:04:05,610 --> 00:04:09,260
is and what the variance of
random variable a is.

73
00:04:09,260 --> 00:04:18,149
So the variance of z-- and just
to kind of always focus

74
00:04:18,149 --> 00:04:20,200
back on the intuition,
it makes sense.

75
00:04:20,200 --> 00:04:24,880
If x is completely independent
of y and if I have some random

76
00:04:24,880 --> 00:04:27,780
variable that is the sum of
the two, then the expected

77
00:04:27,780 --> 00:04:32,440
value of that variable, of that
new variable, is going to

78
00:04:32,440 --> 00:04:35,530
be the sum of the expected
values of the other two

79
00:04:35,530 --> 00:04:37,440
because they are unrelated.

80
00:04:37,440 --> 00:04:41,690
If my expected value here is 5
and my expected value here is

81
00:04:41,690 --> 00:04:46,370
7, completely reasonable that my
expected value here is 12,

82
00:04:46,370 --> 00:04:48,500
assuming that they're completely
independent.

83
00:04:48,500 --> 00:04:54,780
Now if we have a situation, so
what is the variance of my

84
00:04:54,780 --> 00:04:56,070
random variable z?

85
00:04:56,070 --> 00:04:58,390
And once again, I'm not going do
a rigorous proof here, this

86
00:04:58,390 --> 00:05:01,040
is really just a property
of variances.

87
00:05:01,040 --> 00:05:03,840
But I'm going to use this to
establish what the variance of

88
00:05:03,840 --> 00:05:06,450
our random variable a is.

89
00:05:06,450 --> 00:05:11,870
So if this squared distance on
average is some variance, and

90
00:05:11,870 --> 00:05:14,150
this one is completely
independent, it's squared

91
00:05:14,150 --> 00:05:17,410
distance on average is some
distance, then the variance of

92
00:05:17,410 --> 00:05:21,360
their sum is actually going to
be the sum of their variances.

93
00:05:21,360 --> 00:05:29,520
So this is going to be equal
to the variance of random

94
00:05:29,520 --> 00:05:33,723
variable x plus the variance
of random variable y.

95
00:05:33,723 --> 00:05:36,740
   

96
00:05:36,740 --> 00:05:42,870
Or another way of thinking about
it is that the variance

97
00:05:42,870 --> 00:05:52,800
of z, which is the same thing
as the variance of x plus y,

98
00:05:52,800 --> 00:06:02,570
is equal to the variance of x
plus the variance of random

99
00:06:02,570 --> 00:06:04,190
variable y.

100
00:06:04,190 --> 00:06:05,170
Hopefully that make
some sense.

101
00:06:05,170 --> 00:06:06,780
I'm not proving it to
you rigorously.

102
00:06:06,780 --> 00:06:09,130
And you'll see this in a lot
of statistics books.

103
00:06:09,130 --> 00:06:12,330
Now what I want to show you is
that the variance of random

104
00:06:12,330 --> 00:06:15,440
variable a is actually this
exact same thing.

105
00:06:15,440 --> 00:06:17,400
And that's the interesting
thing, because you might say,

106
00:06:17,400 --> 00:06:18,640
hey, why wouldn't it
be the difference?

107
00:06:18,640 --> 00:06:20,100
We had the differences
over here.

108
00:06:20,100 --> 00:06:22,330
So let's experiment with
this a little bit.

109
00:06:22,330 --> 00:06:28,670
The variance-- so I'll just
write this-- the variance of

110
00:06:28,670 --> 00:06:32,750
random variable a is the same
thing as the variance of--

111
00:06:32,750 --> 00:06:39,110
I'll write it like this-- as x
minus y, which is equal to--

112
00:06:39,110 --> 00:06:45,270
you could view it this way--
which is equal to the variance

113
00:06:45,270 --> 00:06:50,630
of x plus negative y.

114
00:06:50,630 --> 00:06:53,240
These are equivalent
statements.

115
00:06:53,240 --> 00:06:56,550
So you could view this as being
equal to-- just using

116
00:06:56,550 --> 00:06:59,610
this over here, the sum of these
two variances, so it's

117
00:06:59,610 --> 00:07:05,050
going to be equal to the sum of
the variance of x plus the

118
00:07:05,050 --> 00:07:08,950
variance of negative y.

119
00:07:08,950 --> 00:07:11,100
Now what I need to show you is
that the variance of negative

120
00:07:11,100 --> 00:07:13,340
y, of the negative of that
random variables are going to

121
00:07:13,340 --> 00:07:15,750
be the same thing as
the variance of y.

122
00:07:15,750 --> 00:07:18,280
So what is the variance
of negative y?

123
00:07:18,280 --> 00:07:23,010
The variance of negative y is
the same thing as the variance

124
00:07:23,010 --> 00:07:32,060
of negative y, which is equal
to the expected value of the

125
00:07:32,060 --> 00:07:42,370
distance between negative y
and the expected value of

126
00:07:42,370 --> 00:07:45,970
negative y squared.

127
00:07:45,970 --> 00:07:50,080
That's all the variance
actually is.

128
00:07:50,080 --> 00:07:56,650
Now what is the expected value
of negative y right over here?

129
00:07:56,650 --> 00:07:59,240
Actually, even better let me
factor out a negative 1.

130
00:07:59,240 --> 00:08:01,420
So what's in the parentheses
right here, this is the exact

131
00:08:01,420 --> 00:08:07,460
same thing as negative 1 squared
times y plus the

132
00:08:07,460 --> 00:08:11,430
expected value of negative y.

133
00:08:11,430 --> 00:08:13,110
So that's the same exact
same thing in the

134
00:08:13,110 --> 00:08:14,670
parentheses, squared.

135
00:08:14,670 --> 00:08:17,120
So everything in magenta is
everything in magenta here,

136
00:08:17,120 --> 00:08:19,090
and it is the expected
value of that thing.

137
00:08:19,090 --> 00:08:22,610
   

138
00:08:22,610 --> 00:08:26,956
Now what is the expected
value of negative y?

139
00:08:26,956 --> 00:08:30,390
The expected value of negative
y-- I'll do it over here-- the

140
00:08:30,390 --> 00:08:33,770
expected value of the negative
of a random variable is just a

141
00:08:33,770 --> 00:08:37,000
negative of the expected value
of that random variable.

142
00:08:37,000 --> 00:08:40,350
So if you look at this we can
re-write this-- I'll give

143
00:08:40,350 --> 00:08:42,860
myself a little bit more space--
we can re-write this

144
00:08:42,860 --> 00:08:46,240
as the expected value-- the
variance of negative y is the

145
00:08:46,240 --> 00:08:47,850
expected value--
this is just 1.

146
00:08:47,850 --> 00:08:49,930
Negative 1 squared is just 1.

147
00:08:49,930 --> 00:08:54,750
And over here you have y, and
instead just write plus the

148
00:08:54,750 --> 00:08:57,530
expected value of negative y,
that's the same thing as minus

149
00:08:57,530 --> 00:09:00,270
the expected value of y.

150
00:09:00,270 --> 00:09:03,140
So you have that, and then
all of that squared.

151
00:09:03,140 --> 00:09:10,160
Now notice, this is the exact
same thing by definition as

152
00:09:10,160 --> 00:09:13,020
the variance of y.

153
00:09:13,020 --> 00:09:15,000
So what we just showed you
just now, so this is the

154
00:09:15,000 --> 00:09:15,720
variance of y.

155
00:09:15,720 --> 00:09:22,340
So we just showed you is that
the variance of the difference

156
00:09:22,340 --> 00:09:27,770
of two independent random
variables is equal to the sum

157
00:09:27,770 --> 00:09:30,950
of the variances.

158
00:09:30,950 --> 00:09:33,810
You could definitely believe
this, it's equal to the sum of

159
00:09:33,810 --> 00:09:37,090
the variance of the first one
plus the variance of the

160
00:09:37,090 --> 00:09:38,720
negative of the second one.

161
00:09:38,720 --> 00:09:41,250
And we just showed that that
variance is the same thing as

162
00:09:41,250 --> 00:09:43,510
the variance of the positive
version of that variable,

163
00:09:43,510 --> 00:09:44,230
which makes sense.

164
00:09:44,230 --> 00:09:47,810
Your distance from the mean is
going to be-- it doesn't

165
00:09:47,810 --> 00:09:49,610
matter whether you're taking the
positive or the negative

166
00:09:49,610 --> 00:09:50,020
of the variable.

167
00:09:50,020 --> 00:09:51,410
You just cared about
absolute distance.

168
00:09:51,410 --> 00:09:54,510
So it makes complete sense that
that quantity and that

169
00:09:54,510 --> 00:09:56,860
quantity is going to
be the same thing.

170
00:09:56,860 --> 00:09:59,040
Now the whole reason why I went
through this exercise,

171
00:09:59,040 --> 00:10:03,360
kind of the important takeaways
here is that the

172
00:10:03,360 --> 00:10:08,810
mean of differences right over
here-- so I could re-write it

173
00:10:08,810 --> 00:10:12,650
as the differences of the random
variable is the same

174
00:10:12,650 --> 00:10:14,760
thing as the differences
of their means.

175
00:10:14,760 --> 00:10:16,600
And then the other important
takeaway, and I'm going to

176
00:10:16,600 --> 00:10:20,220
build on this in the next few
videos, is that the variance

177
00:10:20,220 --> 00:10:24,350
of the difference-- if I define
a new random variable

178
00:10:24,350 --> 00:10:27,420
is the difference of two other
random variables, the variance

179
00:10:27,420 --> 00:10:29,790
of that random variable is
actually the sum of the

180
00:10:29,790 --> 00:10:31,850
variances of the two
random variables.

181
00:10:31,850 --> 00:10:35,030
So these are the two important
takeaways that we'll use to

182
00:10:35,030 --> 00:10:37,010
build on in future videos.

183
00:10:37,010 --> 00:10:39,930
Anyway, hopefully that
wasn't too confusing.

184
00:10:39,930 --> 00:10:42,270
If it was, you can kind of
just accept these at face

185
00:10:42,270 --> 00:10:44,430
value and just assume
that these are tools

186
00:10:44,430 --> 00:10:46,090
that you can use.

187
00:10:46,090 --> 00:10:46,399

