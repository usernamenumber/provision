1
00:00:00,000 --> 00:00:04,333
Here is a simulation created by Khan Academy user tetf

2
00:00:04,333 --> 00:00:07,446
I can assume that's pronounced "tetf."

3
00:00:07,446 --> 00:00:09,992
And what it allows us to do is give us an intuition as

4
00:00:09,992 --> 00:00:13,748
to why we divide by n-1 when we calculate our

5
00:00:13,748 --> 00:00:16,878
sample variance and why that gives us an unbiased

6
00:00:16,878 --> 00:00:19,095
estimate of population variance.

7
00:00:19,095 --> 00:00:22,126
So, the way this starts off (and I encourage you to go try

8
00:00:22,126 --> 00:00:25,376
this out yourself) is that you can construct a distribution

9
00:00:25,376 --> 00:00:28,096
that says, "build a population by clicking in the blue area."

10
00:00:28,096 --> 00:00:32,417
So, here we're actually creating a population

11
00:00:32,432 --> 00:00:35,629
So, we're creating them everytime I click, it increases the population size.

12
00:00:35,629 --> 00:00:40,262
Let me just - and I'm just randomly doing this and I encourage you to go on

13
00:00:40,262 --> 00:00:44,734
to this scratchpad. It's on the Khan Academy Computer Science

14
00:00:44,765 --> 00:00:47,832
and try to do it yourself. So, here

15
00:00:48,171 --> 00:00:52,832
We are - I can stop at some point. So, I've constructed a population

16
00:00:52,832 --> 00:00:54,623
I can throw out some random points up here.

17
00:00:54,623 --> 00:00:57,626
So, this is our population and you saw while I was doing that

18
00:00:57,626 --> 00:00:59,766
it was calculating parameters for the population.

19
00:00:59,766 --> 00:01:04,564
It was calculating the population mean at 204.09 and also

20
00:01:04,564 --> 00:01:08,748
the population standard deviation, which is derived from the population variance.

21
00:01:08,748 --> 00:01:13,364
This is the square root of the population variance and its at 63.8.

22
00:01:13,364 --> 00:01:16,659
It was also plotting the population variance down here.

23
00:01:16,659 --> 00:01:19,415
You see, it's 63.8 which is the standard deviation.

24
00:01:19,415 --> 00:01:22,112
It's a little harder to see but it says squared.

25
00:01:22,112 --> 00:01:25,394
These are these numbers squared. So this is essentially

26
00:01:25,394 --> 00:01:32,828
63.8 squared is the population variance.

27
00:01:32,828 --> 00:01:35,599
So, that's interesting by itself but it really doesn't tell us

28
00:01:35,599 --> 00:01:38,881
a lot, so far, about why we divide by n-1.

29
00:01:38,881 --> 00:01:40,691
And this is the interesting part.

30
00:01:40,691 --> 00:01:43,172
We can now start to take samples and we can decide what

31
00:01:43,172 --> 00:01:46,165
sample size we want to do. I'll start with really small samples.

32
00:01:46,165 --> 00:01:49,330
The smallest possible sample that makes any sense.

33
00:01:49,330 --> 00:01:51,494
So, I'm going to start with really small samples

34
00:01:51,494 --> 00:01:54,131
and what they're going to do, what the simulation is going to do is

35
00:01:54,131 --> 00:01:56,725
every time I take a sample, it's going to calculate the variance.

36
00:01:56,725 --> 00:01:59,977
So, the numerator is going to be the sum of each of my

37
00:01:59,977 --> 00:02:02,930
data points in my sample minus my sample mean.

38
00:02:02,930 --> 00:02:05,504
Then, I'm going to square it. And, then it's going to

39
00:02:05,504 --> 00:02:09,462
divide it by n+a and it's going to vary "a."

40
00:02:09,462 --> 00:02:12,278
It's going to divide it by anywhere from between

41
00:02:12,278 --> 00:02:15,883
n+-3... so, n-3

42
00:02:15,883 --> 00:02:19,393
all the way to n+a, and we're going to do it

43
00:02:19,393 --> 00:02:21,666
many, many, many times. We're going to essentially

44
00:02:21,666 --> 00:02:23,781
take the mean of those variances for any "a"

45
00:02:23,781 --> 00:02:26,884
and figure out which gives us the best estimate.

46
00:02:26,884 --> 00:02:34,291
So, if I just generate one sample right over there. Well, we see a kind of this curve

47
00:02:34,291 --> 00:02:37,732
When we have high values of "a", we are underestimating.

48
00:02:37,732 --> 00:02:42,963
When we have lower values of "a", we are overestimating the population variance.

49
00:02:42,963 --> 00:02:46,983
But, that was just for one sample, not really that meaningful.

50
00:02:46,983 --> 00:02:48,581
It's one sample size too.

51
00:02:48,581 --> 00:02:51,478
Let's generate a bunch of samples and then average them

52
00:02:51,478 --> 00:02:54,859
over many of them. And, when you look at many, many

53
00:02:54,859 --> 00:02:58,110
many samples, something interesting is happening.

54
00:02:58,110 --> 00:03:01,096
When you look at the mean of those samples

55
00:03:01,096 --> 00:03:03,744
when you average together those curves from all of those samples

56
00:03:03,744 --> 00:03:08,468
you see that our best estimate is when "a" is pretty close to -1

57
00:03:08,468 --> 00:03:13,175
When this is n+-1 or n-1

58
00:03:13,175 --> 00:03:15,819
Anything less than -1, if we did

59
00:03:15,819 --> 00:03:22,298
negative n-1.05 or n-1.5, we start overestimating the variance

60
00:03:22,298 --> 00:03:26,758
Anything less than -1, so if we start

61
00:03:26,758 --> 00:03:34,059
if we have n+0, if we divide by n, or if we have n+0.05 or

62
00:03:34,059 --> 00:03:38,494
whatever it might be, we start underestimating

63
00:03:38,494 --> 00:03:40,121
the population variance.

64
00:03:40,121 --> 00:03:42,287
And you can do this for samples of different sizes.

65
00:03:42,287 --> 00:03:44,855
Let me try sample size 6.

66
00:03:44,855 --> 00:03:47,313
And here you go, once again, as I press

67
00:03:47,313 --> 00:03:49,429
I'm just keeping "Generate Sample" pressed down.

68
00:03:49,429 --> 00:03:51,525
As we generate more and more of more samples

69
00:03:51,525 --> 00:03:56,807
for all of the a's, we essentially take the average across all of those samples

70
00:03:56,807 --> 00:03:58,974
for the variance, depending on how we calculated it

71
00:03:58,974 --> 00:04:04,983
you'll see that, once again, our best estimate is pretty darn close

72
00:04:04,983 --> 00:04:07,457
to -1. And if you were to try this

73
00:04:07,457 --> 00:04:10,977
If you were to get this to millions of samples generated

74
00:04:10,977 --> 00:04:13,705
you will see that your best estimate is when

75
00:04:13,705 --> 00:04:20,697
a is -1, or when you're dividing by n-1.

76
00:04:20,697 --> 00:04:23,342
So, once again, thanks "tetf" for this

77
00:04:23,342 --> 00:04:26,507
I think its a really interesting way to think about

78
00:04:26,507 --> 00:04:30,000
why we divide by n-1.
