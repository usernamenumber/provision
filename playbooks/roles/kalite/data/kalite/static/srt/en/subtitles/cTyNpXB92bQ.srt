1
00:00:00,000 --> 00:00:00,670
   

2
00:00:00,670 --> 00:00:04,100
We've defined the notion of a
projection onto a subspace,

3
00:00:04,100 --> 00:00:06,870
but I haven't shown you yet that
it's definitely a linear

4
00:00:06,870 --> 00:00:07,960
transformation.

5
00:00:07,960 --> 00:00:10,965
Nor have I shown you that if
you know a basis for a

6
00:00:10,965 --> 00:00:13,990
subspace, how do you actually
find a projection onto it?

7
00:00:13,990 --> 00:00:17,080
So let's see if we can make
any progress on that here.

8
00:00:17,080 --> 00:00:19,220
So let's say I have
some subspace.

9
00:00:19,220 --> 00:00:28,750
Let's say v is a
subspace of Rn.

10
00:00:28,750 --> 00:00:31,720
And let's say I've got some
basis vectors for v.

11
00:00:31,720 --> 00:00:35,610
So let's say these are my basis
vectors, basis vector 1,

12
00:00:35,610 --> 00:00:39,160
2, and I have k of them.

13
00:00:39,160 --> 00:00:41,520
I don't know what v's
dimension is, but

14
00:00:41,520 --> 00:00:42,760
let's say it's k.

15
00:00:42,760 --> 00:00:52,230
It's got k basis vectors,
so it is a basis for v.

16
00:00:52,230 --> 00:00:56,680
And that means that any vector--
that's not v vector,

17
00:00:56,680 --> 00:01:02,840
that's v subspace-- now that
means that any vector-- let me

18
00:01:02,840 --> 00:01:07,100
call some vector, I don't know,
let's say, any vector a

19
00:01:07,100 --> 00:01:10,740
that is a member of my subspace
can be represented.

20
00:01:10,740 --> 00:01:13,170
That means that a can be
represented as a linear

21
00:01:13,170 --> 00:01:15,190
combination of these guys.

22
00:01:15,190 --> 00:01:17,040
So I'll make my linear
combination.

23
00:01:17,040 --> 00:01:25,130
Let's say it is, I don't know,
y1 times b1, plus y2 times b2,

24
00:01:25,130 --> 00:01:30,700
all the way to plus
yk times bk.

25
00:01:30,700 --> 00:01:32,370
That's what the definition
of a basis is.

26
00:01:32,370 --> 00:01:36,590
The span of these guys is your
subspace v, so any member of v

27
00:01:36,590 --> 00:01:37,830
can be represented as a linear

28
00:01:37,830 --> 00:01:40,220
combination of my basis vectors.

29
00:01:40,220 --> 00:01:47,340
Now, if I were to construct a
matrix-- let's make it an n by

30
00:01:47,340 --> 00:01:51,890
k matrix-- whose columns are
essentially the basis vectors

31
00:01:51,890 --> 00:01:53,930
of my subspace.

32
00:01:53,930 --> 00:01:56,430
So A looks like this,
the first column is

33
00:01:56,430 --> 00:01:58,310
my first basis vector.

34
00:01:58,310 --> 00:02:01,800
My second column is my second
basis vector, and I go all the

35
00:02:01,800 --> 00:02:05,280
way to my k column, and I have
k columns, is going to be my

36
00:02:05,280 --> 00:02:07,610
k'th basis vector.

37
00:02:07,610 --> 00:02:10,449
If I'm going to have my k'th
basis vector-- let me make the

38
00:02:10,449 --> 00:02:14,140
closing bracket the same color
as my opening bracket, just

39
00:02:14,140 --> 00:02:16,500
like that-- it's going to have
n rows, because each of these

40
00:02:16,500 --> 00:02:18,360
basis vectors are
members of Rn.

41
00:02:18,360 --> 00:02:21,140
Remember, v is a subspace of Rn,
so each of these guys are

42
00:02:21,140 --> 00:02:23,730
going to have n terms.
So this matrix is

43
00:02:23,730 --> 00:02:25,560
going to have n rows.

44
00:02:25,560 --> 00:02:29,620
Now, saying that any member
of the subspace v can be

45
00:02:29,620 --> 00:02:31,980
represented as a linear
combination of these basis

46
00:02:31,980 --> 00:02:36,360
vectors, is equivalent to saying
that any member, that

47
00:02:36,360 --> 00:02:43,170
a, that any member a of our
subspace v can be represented

48
00:02:43,170 --> 00:02:57,540
as the product of our matrix A,
times some vector y, where

49
00:02:57,540 --> 00:02:57,820
[INAUDIBLE]

50
00:02:57,820 --> 00:03:06,980
was equal to a, for some y,
that is a member of Rk.

51
00:03:06,980 --> 00:03:09,940
Now why is this statement and
that statement equivalent?

52
00:03:09,940 --> 00:03:12,600
Well you can imagine, if you
were to just multiply this

53
00:03:12,600 --> 00:03:20,110
times some vector y in Rk, so
it's y1, y2, all the way down

54
00:03:20,110 --> 00:03:27,090
to yk, this is going to be equal
to y1 times v1, plus y2,

55
00:03:27,090 --> 00:03:35,960
times b2, all the way to plus yk
times bk, which is the same

56
00:03:35,960 --> 00:03:36,280
thing as this.

57
00:03:36,280 --> 00:03:39,990
So you can always pick the
right linear combination.

58
00:03:39,990 --> 00:03:43,200
You can always pick the right
member, yk, so that you get

59
00:03:43,200 --> 00:03:45,720
the right linear combination of
your basis vectors to get

60
00:03:45,720 --> 00:03:48,500
any member of your subspace v.

61
00:03:48,500 --> 00:03:51,860
So any member of my subspace,
right there, can be

62
00:03:51,860 --> 00:03:56,930
represented as the product
of the matrix A with

63
00:03:56,930 --> 00:03:59,980
some vector in Rk.

64
00:03:59,980 --> 00:04:03,140
Now we don't know much about
this vector here in Rk.

65
00:04:03,140 --> 00:04:07,980
Now, the projection-- let's
say that x is just some

66
00:04:07,980 --> 00:04:17,620
arbitrary member of Rn-- the
projection of x onto our

67
00:04:17,620 --> 00:04:21,620
subspace v, that is by
definition going to be a

68
00:04:21,620 --> 00:04:23,890
member of your subspace.

69
00:04:23,890 --> 00:04:30,540
Or another way of saying it is
that this guy, the projection

70
00:04:30,540 --> 00:04:36,380
onto v of x is going to be equal
to my matrix A, is going

71
00:04:36,380 --> 00:04:39,320
to be equal to-- I'll do it in
blue-- is going to be equal to

72
00:04:39,320 --> 00:04:50,360
A times some vector y, or
some vector y in Rk.

73
00:04:50,360 --> 00:04:54,250
If we knew what that vector y
was, if we could always find

74
00:04:54,250 --> 00:04:58,060
it, then we would have a
formula, so to speak, for

75
00:04:58,060 --> 00:05:00,040
figuring out the projection
of x onto v.

76
00:05:00,040 --> 00:05:01,420
But we don't have that yet.

77
00:05:01,420 --> 00:05:07,160
All I've said is, any member of
v can be represented as a

78
00:05:07,160 --> 00:05:12,760
product of our matrix A, which
has the basis for v as

79
00:05:12,760 --> 00:05:15,260
columns, and some
member of Rk.

80
00:05:15,260 --> 00:05:18,670
That just comes out of the fact
that these guys span v,

81
00:05:18,670 --> 00:05:19,960
that any member of
v is a linear

82
00:05:19,960 --> 00:05:21,580
combination of those guys.

83
00:05:21,580 --> 00:05:25,620
We know that the projection of
x onto v is a member of our

84
00:05:25,620 --> 00:05:28,760
subspace v, it has to
be inside of v.

85
00:05:28,760 --> 00:05:32,550
So it can also be represented
this way.

86
00:05:32,550 --> 00:05:35,740
Now what was our definition
of our projection?

87
00:05:35,740 --> 00:05:38,420
Our definition of our
projection, we say--

88
00:05:38,420 --> 00:05:39,330
Well, let me write
it this way.

89
00:05:39,330 --> 00:05:46,850
We know that x can be
represented as the sum of the

90
00:05:46,850 --> 00:05:55,910
projection onto v of x, plus
some member of v complement.

91
00:05:55,910 --> 00:06:04,140
Or maybe I could even write,
plus the projection onto the

92
00:06:04,140 --> 00:06:06,410
orthogonal complement of v.

93
00:06:06,410 --> 00:06:11,710
   

94
00:06:11,710 --> 00:06:12,620
You could write this way.

95
00:06:12,620 --> 00:06:16,810
I could have also written this
as w, where w is a member of v

96
00:06:16,810 --> 00:06:17,170
complement.

97
00:06:17,170 --> 00:06:18,160
Actually, let me write
it that way.

98
00:06:18,160 --> 00:06:19,140
That might make it simpler.

99
00:06:19,140 --> 00:06:23,720
I don't want to get too many
projections here-- plus w,

100
00:06:23,720 --> 00:06:37,800
where w is a unique member
of the orthogonal

101
00:06:37,800 --> 00:06:39,420
complement of v.

102
00:06:39,420 --> 00:06:42,610
Or you could say it this way,
if you subtract a projection

103
00:06:42,610 --> 00:06:48,900
of x onto v from both sides, you
get x minus the projection

104
00:06:48,900 --> 00:06:52,285
of x onto v, is equal to w.

105
00:06:52,285 --> 00:06:54,790
   

106
00:06:54,790 --> 00:06:57,510
Or another way to say it is that
this guy right here is

107
00:06:57,510 --> 00:07:01,280
going to be a member of the
orthogonal complement of v,

108
00:07:01,280 --> 00:07:03,700
right, because this is
the same thing as w.

109
00:07:03,700 --> 00:07:06,840
Now what's the orthogonal
complement of v?

110
00:07:06,840 --> 00:07:09,070
We go back to this
matrix here.

111
00:07:09,070 --> 00:07:11,500
I have these basis vectors.

112
00:07:11,500 --> 00:07:13,410
Right here is the columns.

113
00:07:13,410 --> 00:07:21,310
So the column space of A is
going to be equal to v, right?

114
00:07:21,310 --> 00:07:23,720
The column space of
A is just the span

115
00:07:23,720 --> 00:07:25,100
of these basis vectors.

116
00:07:25,100 --> 00:07:28,420
And by definition, that is
going to be equal to my

117
00:07:28,420 --> 00:07:29,630
subspace v.

118
00:07:29,630 --> 00:07:32,760
Now what is the orthogonal
complement of v?

119
00:07:32,760 --> 00:07:36,200
The orthogonal complement of v
is going to be the orthogonal

120
00:07:36,200 --> 00:07:37,920
complement of my column space.

121
00:07:37,920 --> 00:07:42,420
   

122
00:07:42,420 --> 00:07:46,160
And what's the orthogonal
complement of a column space?

123
00:07:46,160 --> 00:07:50,840
That's equal to the null space
of A transpose, or you could

124
00:07:50,840 --> 00:07:53,750
also call that the left
null space of A.

125
00:07:53,750 --> 00:07:56,600
But we've seen that many,
many, videos ago.

126
00:07:56,600 --> 00:08:00,980
So we could say that x minus the
projection of x onto v as

127
00:08:00,980 --> 00:08:07,240
a member of-- let me write
it this way-- x minus the

128
00:08:07,240 --> 00:08:14,230
projection onto v of x is a
member of the orthogonal

129
00:08:14,230 --> 00:08:18,050
complement of my column space
of my matrix, which is equal

130
00:08:18,050 --> 00:08:22,870
to the null space
of A transpose.

131
00:08:22,870 --> 00:08:25,210
That's the orthogonal
complement of v.

132
00:08:25,210 --> 00:08:28,810
This is the same thing as the
orthogonal complement of v.

133
00:08:28,810 --> 00:08:30,540
But what does this mean?

134
00:08:30,540 --> 00:08:31,910
What does this mean
right here?

135
00:08:31,910 --> 00:08:36,640
This means that if I take A
transpose, and I multiply it

136
00:08:36,640 --> 00:08:39,200
times this vector, because it's
a member of A transpose's

137
00:08:39,200 --> 00:08:40,580
null space.

138
00:08:40,580 --> 00:08:44,540
So if I multiply it times that
vector right there-- so,

139
00:08:44,540 --> 00:08:48,470
projection of x onto v-- then
I'm going to get 0.

140
00:08:48,470 --> 00:08:49,840
I'm going to get the 0 vector.

141
00:08:49,840 --> 00:08:52,160
That's the definition
of a null space.

142
00:08:52,160 --> 00:08:53,730
So let's write this out
a little bit more.

143
00:08:53,730 --> 00:08:54,990
Let's see if we can
algebraically

144
00:08:54,990 --> 00:08:56,240
manipulate it a bit.

145
00:08:56,240 --> 00:08:59,020
So if we distribute this matrix
vector product, we get

146
00:08:59,020 --> 00:09:06,150
A transpose times the vector
x, minus A transpose, times

147
00:09:06,150 --> 00:09:13,520
the projection-- actually let
me write this this way.

148
00:09:13,520 --> 00:09:16,400
Instead of keep writing the
projection onto v of x, what

149
00:09:16,400 --> 00:09:17,820
did we say earlier
in this video?

150
00:09:17,820 --> 00:09:22,900
We said the projection of v onto
x can be represented as

151
00:09:22,900 --> 00:09:26,750
the matrix product of
the matrix A, times

152
00:09:26,750 --> 00:09:29,330
some vector y in Rk.

153
00:09:29,330 --> 00:09:30,690
That's where we started
off the video.

154
00:09:30,690 --> 00:09:32,240
So let me write it that way,
because that's what going to

155
00:09:32,240 --> 00:09:34,050
simplify our work
a little bit.

156
00:09:34,050 --> 00:09:37,460
So I'm going to distribute
the A transpose, A

157
00:09:37,460 --> 00:09:38,560
transpose times x.

158
00:09:38,560 --> 00:09:41,300
And then A transpose, minus A
transpose, times this thing.

159
00:09:41,300 --> 00:09:49,300
This thing I can write as A
times some vector y, and this

160
00:09:49,300 --> 00:09:52,460
is just a byproduct of the
notion that the projection is

161
00:09:52,460 --> 00:09:54,220
a member of our subspace.

162
00:09:54,220 --> 00:09:56,140
Because it's a member of our
subspace, it's going to be

163
00:09:56,140 --> 00:09:59,480
some linear combination of
the column vectors of A.

164
00:09:59,480 --> 00:10:04,800
We saw that up here, so it can
be represented in this way.

165
00:10:04,800 --> 00:10:12,400
So instead of projection onto
v of x, I can just write Ay.

166
00:10:12,400 --> 00:10:16,500
This thing and this thing are
equivalent, because this thing

167
00:10:16,500 --> 00:10:17,940
is a member of v.

168
00:10:17,940 --> 00:10:21,250
And then all of that is going
to be equal to 0.

169
00:10:21,250 --> 00:10:24,980
And then if we add this to both
sides of this equation,

170
00:10:24,980 --> 00:10:38,500
we get that A transpose x is
equal to A transpose A of y.

171
00:10:38,500 --> 00:10:39,580
Now this is interesting.

172
00:10:39,580 --> 00:10:41,590
Remember where we started
off here.

173
00:10:41,590 --> 00:10:50,010
We said that the projection onto
v of x is equal to Ay for

174
00:10:50,010 --> 00:10:56,040
some y that is a member of Rk.

175
00:10:56,040 --> 00:10:59,160
If we knew what that y was, if
we could always solve for that

176
00:10:59,160 --> 00:11:02,450
y, then the projection of
x would be well defined.

177
00:11:02,450 --> 00:11:05,230
And we could always just
figure it out.

178
00:11:05,230 --> 00:11:07,840
Now can we solve for y here?

179
00:11:07,840 --> 00:11:11,070
Well, we'll be able to solve
for y if we can take the

180
00:11:11,070 --> 00:11:13,250
inverse of that matrix.

181
00:11:13,250 --> 00:11:16,360
If this major is always
invertible, then we're always

182
00:11:16,360 --> 00:11:17,870
going to be able to
solve for y here.

183
00:11:17,870 --> 00:11:20,370
Because we just take the inverse
of this matrix and

184
00:11:20,370 --> 00:11:22,120
multiply it times the
left side of both

185
00:11:22,120 --> 00:11:23,660
sides in this equation.

186
00:11:23,660 --> 00:11:28,450
Now if you remember, three
videos ago, I think it was

187
00:11:28,450 --> 00:11:34,180
three videos ago, I showed you
that if I have a matrix A

188
00:11:34,180 --> 00:11:43,220
whose columns are linearly
independent, then A transpose

189
00:11:43,220 --> 00:11:48,890
A is always invertible.

190
00:11:48,890 --> 00:11:51,580
The whole reason why I did that
video was for this moment

191
00:11:51,580 --> 00:11:52,930
right here.

192
00:11:52,930 --> 00:11:56,430
Now, what about our matrix A?

193
00:11:56,430 --> 00:11:59,650
Well, our matrix A has column
vectors that form the basis

194
00:11:59,650 --> 00:12:00,500
for a subspace.

195
00:12:00,500 --> 00:12:03,740
By definition, basis vectors
are linearly independent.

196
00:12:03,740 --> 00:12:07,510
So our matrix A has columns that
are linearly independent.

197
00:12:07,510 --> 00:12:09,850
And if you watched that video,
and if you believe what I told

198
00:12:09,850 --> 00:12:13,470
you, then you'll know that A
transpose A, in our case, is

199
00:12:13,470 --> 00:12:14,760
going to be invertible.

200
00:12:14,760 --> 00:12:16,570
It has to be inveritible.

201
00:12:16,570 --> 00:12:19,330
So let's take the inverse
of it and multiply

202
00:12:19,330 --> 00:12:20,350
it times both sides.

203
00:12:20,350 --> 00:12:24,940
If we take A transpose A
inverse-- we know that this

204
00:12:24,940 --> 00:12:29,030
exists, because A has linearly
independent columns-- and

205
00:12:29,030 --> 00:12:34,080
multiply it times this side
right here, A transpose x.

206
00:12:34,080 --> 00:12:37,430
And then on this side we get--
well, we're going to do the

207
00:12:37,430 --> 00:12:43,080
same thing-- A transpose A
inverse, times this thing

208
00:12:43,080 --> 00:12:47,060
right here, A transpose Ay.

209
00:12:47,060 --> 00:12:48,920
These two things when you
multiply them, when you

210
00:12:48,920 --> 00:12:51,340
multiply the inverse of a
matrix, times the matrix,

211
00:12:51,340 --> 00:12:53,470
you're just going to get
the identity matrix.

212
00:12:53,470 --> 00:12:56,910
So that's just going to be equal
to the identity matrix.

213
00:12:56,910 --> 00:12:59,880
And the identity matrix times y
is just going to be y, so we

214
00:12:59,880 --> 00:13:02,790
get-- and this is a vector--
so if I flip them around, I

215
00:13:02,790 --> 00:13:09,080
get that y is equal to this
expression right here.

216
00:13:09,080 --> 00:13:14,720
A transpose A inverse, which'll
always exist, times A

217
00:13:14,720 --> 00:13:17,120
transpose, times x.

218
00:13:17,120 --> 00:13:20,970
Now we said the projection of x
onto v is going to be equal

219
00:13:20,970 --> 00:13:23,410
to A times y, for some y.

220
00:13:23,410 --> 00:13:26,660
Well we just solved for the y
using our definition of a

221
00:13:26,660 --> 00:13:27,180
projection.

222
00:13:27,180 --> 00:13:28,700
We just were able
to solve for y.

223
00:13:28,700 --> 00:13:34,710
So now, we can define our
projection of x onto v as a

224
00:13:34,710 --> 00:13:36,590
matrix vector product.

225
00:13:36,590 --> 00:13:44,020
So we can write the projection
onto v of our vector x is

226
00:13:44,020 --> 00:13:51,030
equal to A, times y, and
y is just equal to

227
00:13:51,030 --> 00:13:52,280
that thing right there.

228
00:13:52,280 --> 00:13:54,800
   

229
00:13:54,800 --> 00:14:01,630
So A times A transpose A
inverse-- which always exists

230
00:14:01,630 --> 00:14:05,600
because A has linearly
independent columns-- times A

231
00:14:05,600 --> 00:14:08,010
transpose, times x.

232
00:14:08,010 --> 00:14:10,480
And this thing right here, this
long convoluted thing,

233
00:14:10,480 --> 00:14:15,880
that's just some matrix, some
matrix which always exists for

234
00:14:15,880 --> 00:14:18,980
any subspace that
has some basis.

235
00:14:18,980 --> 00:14:22,200
So we've just been able to
express the projection of x

236
00:14:22,200 --> 00:14:27,340
onto a subspace as a matrix
vector product.

237
00:14:27,340 --> 00:14:29,920
So anything that can be any
matrix vector product

238
00:14:29,920 --> 00:14:31,670
transformation is a linear
transformation.

239
00:14:31,670 --> 00:14:35,250
   

240
00:14:35,250 --> 00:14:37,710
And not only did we show that
it's a linear transformation,

241
00:14:37,710 --> 00:14:45,420
we showed that, look, if you can
give me the basis for v,

242
00:14:45,420 --> 00:14:48,810
I'm going to make those column
vectors equal to the column of

243
00:14:48,810 --> 00:14:50,080
some matrix A.

244
00:14:50,080 --> 00:14:53,250
And then if I take matrix A, if
I take its transpose, if I

245
00:14:53,250 --> 00:14:56,910
take A transpose times A, and
invert it, and if I multiply

246
00:14:56,910 --> 00:14:59,130
them all out in this way,
I'm going to get the

247
00:14:59,130 --> 00:15:02,000
transformation matrix
for the projection.

248
00:15:02,000 --> 00:15:04,440
Now this might seem really
complicated, and it is hard to

249
00:15:04,440 --> 00:15:07,720
do by hand for many, many
projections, but this is super

250
00:15:07,720 --> 00:15:10,340
useful if you're going to do
some three-dimensional

251
00:15:10,340 --> 00:15:11,590
graphical programming.

252
00:15:11,590 --> 00:15:15,150
   

253
00:15:15,150 --> 00:15:25,370
Let's say you have some
three-dimensional object, and

254
00:15:25,370 --> 00:15:28,000
you want to know what it looks
like from the point of view of

255
00:15:28,000 --> 00:15:29,185
some observer.

256
00:15:29,185 --> 00:15:30,890
So let's say you have
some observer.

257
00:15:30,890 --> 00:15:34,270
Some observer's point of view
is essentially going to be

258
00:15:34,270 --> 00:15:36,020
some subspace.

259
00:15:36,020 --> 00:15:38,440
You want to see what the
projection of this cube onto

260
00:15:38,440 --> 00:15:41,970
the subspace, how would it
look to the person who's

261
00:15:41,970 --> 00:15:44,260
essentially on to this flat
screen right there.

262
00:15:44,260 --> 00:15:47,610
How would that cube look from
this point of view?

263
00:15:47,610 --> 00:15:51,890
Well if you know the basis for
this subspace, you can just

264
00:15:51,890 --> 00:15:54,260
apply this transformation.

265
00:15:54,260 --> 00:15:57,810
You can make a matrix whose
columns are these basis

266
00:15:57,810 --> 00:16:00,790
vectors for this observer's
point of view.

267
00:16:00,790 --> 00:16:04,860
And then you can apply this to
every vector in this cube in

268
00:16:04,860 --> 00:16:09,420
R3, and you'll know exactly how
this cube should look from

269
00:16:09,420 --> 00:16:11,030
this person's point of view.

270
00:16:11,030 --> 00:16:14,200
So this is actually a
super useful result.

271
00:16:14,200 --> 00:16:14,933

